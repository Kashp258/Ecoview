<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Tree Enumeration</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <link rel="stylesheet" href="/src/assets/css/predict.css">
</head>
<body>
    <header>
        <h1>Tree Enumeration</h1>
    </header>
    <main>
        <input id="uploadInput" type="file"/>
        <canvas></canvas>
        <div id="objectCount" style="position:fixed;left:16px;bottom:16px;background:rgba(0,0,0,0.6);color:#feda6a;padding:8px 12px;border-radius:10px;font-weight:700;border:1px solid rgba(254,218,106,0.5);backdrop-filter: blur(6px);z-index:10;">Detected Trees: 0</div>
        <script>
            // ... Your existing JavaScript code ...
       /**
             * "Upload" button onClick handler: uploads selected image file
             * to backend, receives array of detected objects
             * and draws them on top of image
             */
             const input = document.getElementById("uploadInput");
             input.addEventListener("change",async(event) => {
                 const boxes = await detect_objects_on_image(event.target.files[0]);
                 draw_image_and_boxes(event.target.files[0],boxes);
             })
      

            const confidenceThreshold = 0.35; // Minimum confidence shown on the canvas

            /**
             * Function draws the image from provided file
             * and bounding boxes of detected objects on
             * top of the image
             * @param file Uploaded file object
             * @param boxes Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...]
             */
             
  function draw_image_and_boxes(file, boxes) {
  const img = new Image()
  img.src = URL.createObjectURL(file);
  img.onload = () => {
    const canvas = document.querySelector("canvas");
    canvas.width = img.width;
    canvas.height = img.height;
    const ctx = canvas.getContext("2d");
    ctx.drawImage(img, 0, 0);
    ctx.strokeStyle = "#00FF00";
    ctx.lineWidth = 3;
    ctx.font = "18px serif";

    const confidentBoxes = boxes.filter(([, , , , , prob]) => prob >= confidenceThreshold);
    confidentBoxes.forEach(([x1, y1, x2, y2, label, prob]) => {
      ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
      ctx.fillStyle = "#00ff00";
      const text = `${label} (${(prob * 100).toFixed(2)}%)`;
      const width = ctx.measureText(text).width;
      ctx.fillRect(x1, y1, width + 10, 25);
      ctx.fillStyle = "#000000";
      ctx.fillText(text, x1, y1 + 18);
    });

    // Display the count of detected objects
    document.getElementById("objectCount").textContent = `Detected Trees: ${confidentBoxes.length}`;
  }
}



            /**
             * Function receives an image, passes it through YOLOv8 neural network
             * and returns an array of detected objects and their bounding boxes
             * @param buf Input image body
             * @returns Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],..]
             */
            async function detect_objects_on_image(buf) {
                const [input,img_width,img_height] = await prepare_input(buf);
                const output = await run_model(input);
                return process_output(output,img_width,img_height);
            }
      
            /**
             * Function used to convert input image to tensor,
             * required as an input to YOLOv8 object detection
             * network.
             * @param buf Content of uploaded file
             * @returns Array of pixels
             */
            async function prepare_input(buf) {
                return new Promise(resolve => {
                    const img = new Image();
                    img.src = URL.createObjectURL(buf);
                    img.onload = () => {
                        const img_width = img.width;
                        const img_height = img.height;

                        // Letterbox resize to 640x640 while preserving aspect ratio
                        const canvas = document.createElement("canvas");
                        canvas.width = 640;
                        canvas.height = 640;
                        const ctx = canvas.getContext("2d");
                        ctx.fillStyle = "#000";
                        ctx.fillRect(0,0,640,640);

                        const scale = Math.min(640 / img_width, 640 / img_height);
                        const newW = Math.round(img_width * scale);
                        const newH = Math.round(img_height * scale);
                        const padX = Math.floor((640 - newW) / 2);
                        const padY = Math.floor((640 - newH) / 2);

                        ctx.drawImage(img, 0, 0, img_width, img_height, padX, padY, newW, newH);

                        const imgData = ctx.getImageData(0,0,640,640);
                        const pixels = imgData.data;
                        const red = [], green = [], blue = [];
                        for (let index=0; index<pixels.length; index+=4) {
                            // Normalize to [0,1]
                            red.push(pixels[index] / 255.0);
                            green.push(pixels[index+1] / 255.0);
                            blue.push(pixels[index+2] / 255.0);
                        }
                        const input = [...red, ...green, ...blue];
                        // Save transform for box mapping in process_output
                        window.__lastScale = scale;
                        window.__lastPadX = padX;
                        window.__lastPadY = padY;
                        // return original dims
                        resolve([ { data: input, scale, padX, padY }, img_width, img_height ])
                    }
                })
            }
      
            /**
             * Function used to pass provided input tensor to YOLOv8 neural network and return result
             * @param input Input pixels array
             * @returns Raw output of neural network as a flat array of numbers
             */
            async function run_model(input) {
                const model = await ort.InferenceSession.create("https://ml-cdn.vipulchaturvedi.com/100going1000.onnx");
                const tensor = new ort.Tensor(Float32Array.from(input.data),[1, 3, 640, 640]);
                const outputs = await model.run({images:tensor});
                return outputs["output0"].data;
            }
      
            /*
             * Function used to convert RAW output from YOLOv8 to an array of detected objects.
             * Each object contain the bounding box of this object, the type of object and the probability
             * @param output Raw output of YOLOv8 network
             * @param img_width Width of original image
             * @param img_height Height of original image
             * @returns Array of detected objects in a format [[x1,y1,x2,y2,object_type,probability],..]
             */
            function process_output(output, img_width, img_height) {
                let boxes = [];
                for (let index=0;index<8400;index++) {
                    const [class_id,prob] = [...Array(80).keys()]
                        .map(col => [col, output[8400*(col+4)+index]])
                        .reduce((accum, item) => item[1]>accum[1] ? item : accum,[0,0]);
                    if (prob < 0.35) {
                        continue;
                    }
                    const label = yolo_classes[class_id];
                    const xc = output[index];
                    const yc = output[8400+index];
                    const w = output[2*8400+index];
                    const h = output[3*8400+index];
                    // Reverse letterbox
                    const scale = window.__lastScale || 1;
                    const padX = window.__lastPadX || 0;
                    const padY = window.__lastPadY || 0;
                    const x1n = (xc - w/2) - padX;
                    const y1n = (yc - h/2) - padY;
                    const x2n = (xc + w/2) - padX;
                    const y2n = (yc + h/2) - padY;
                    const x1 = (x1n/ (640 - 0)) * (img_width / scale);
                    const y1 = (y1n/ (640 - 0)) * (img_height / scale);
                    const x2 = (x2n/ (640 - 0)) * (img_width / scale);
                    const y2 = (y2n/ (640 - 0)) * (img_height / scale);
                    boxes.push([x1, y1, x2, y2, label, prob]);
                }
      
                boxes = boxes.sort((box1,box2) => box2[5]-box1[5])
                const result = [];
                while (boxes.length>0) {
                    result.push(boxes[0]);
                    boxes = boxes.filter(box => iou(boxes[0],box)<0.6);
                }
                return result;
            }
      
            /**
             * Function calculates "Intersection-over-union" coefficient for specified two boxes
             * https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/.
             * @param box1 First box in format: [x1,y1,x2,y2,object_class,probability]
             * @param box2 Second box in format: [x1,y1,x2,y2,object_class,probability]
             * @returns Intersection over union ratio as a float number
             */
            function iou(box1,box2) {
                return intersection(box1,box2)/union(box1,box2);
            }
      
            /**
             * Function calculates union area of two boxes.
             *     :param box1: First box in format [x1,y1,x2,y2,object_class,probability]
             *     :param box2: Second box in format [x1,y1,x2,y2,object_class,probability]
             *     :return: Area of the boxes union as a float number
             * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
             * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
             * @returns Area of the boxes union as a float number
             */
            function union(box1,box2) {
                const [box1_x1,box1_y1,box1_x2,box1_y2] = box1;
                const [box2_x1,box2_y1,box2_x2,box2_y2] = box2;
                const box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)
                const box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)
                return box1_area + box2_area - intersection(box1,box2)
            }
      
            /**
             * Function calculates intersection area of two boxes
             * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
             * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
             * @returns Area of intersection of the boxes as a float number
             */
            function intersection(box1,box2) {
                const [box1_x1,box1_y1,box1_x2,box1_y2] = box1;
                const [box2_x1,box2_y1,box2_x2,box2_y2] = box2;
                const x1 = Math.max(box1_x1,box2_x1);
                const y1 = Math.max(box1_y1,box2_y1);
                const x2 = Math.min(box1_x2,box2_x2);
                const y2 = Math.min(box1_y2,box2_y2);
                return (x2-x1)*(y2-y1)
            }
      
            /**
             * Array of YOLOv8 class labels
             */
            const yolo_classes = [
                'tree'
            ];
            /**
             * Function draws the image from provided file
             * and bounding boxes of detected objects on
             * top of the image
             * @param file Uploaded file object
             * @param boxes Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...]
             */
            function draw_image_and_boxes(file, boxes) {
                const img = new Image()
                img.src = URL.createObjectURL(file);
                img.onload = () => {
                    const canvas = document.querySelector("canvas");
                    canvas.width = img.width;
                    canvas.height = img.height;
                    const ctx = canvas.getContext("2d");
                    ctx.drawImage(img,0,0);
                    const confidentBoxes = boxes.filter(([, , , , , prob]) => prob >= confidenceThreshold);
                    ctx.strokeStyle = "#00FF00";
                    ctx.lineWidth = 3;
                    ctx.font = "18px serif";
                    confidentBoxes.forEach(([x1,y1,x2,y2,label,prob]) => {
                        ctx.strokeRect(x1,y1,x2-x1,y2-y1);
                        ctx.fillStyle = "#00ff00";
                        const text = `${label} (${(prob * 100).toFixed(2)}%)`;
                        const width = ctx.measureText(text).width;
                        ctx.fillRect(x1,y1,width+10,25);
                        ctx.fillStyle = "#000000";
                        ctx.fillText(text, x1, y1+18);
                    });
      
                    // Display the count of detected objects
                    document.getElementById("objectCount").textContent = `Detected Trees: ${confidentBoxes.length}`;
                }
            }
      
            // ... Rest of your code ...
      
          </script>
    </main>
</body>
</html>